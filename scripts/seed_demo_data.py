# scripts/seed_demo_data.py

from pathlib import Path


def ensure_file(path: Path, content: str) -> None:
    path.parent.mkdir(parents=True, exist_ok=True)
    if not path.exists():
        path.write_text(content.strip() + "\n", encoding="utf-8")


def main() -> None:
    root = Path(__file__).resolve().parents[1]
    demo_repos = root / "demo_data" / "demo_repos"

    # ------------------------------------------------------------------------------------
    # DOCOPS-SAAS — документация сервисов, API, CI/CD, архитектура
    # ------------------------------------------------------------------------------------
    ensure_file(
        demo_repos / "docops-saas" / "README.md",
        """
# DocOps SaaS Platform

## Назначение

DocOps SaaS Platform — тестовый проект, предназначенный для демонстрации функциональности DocOps MCP Assistant. Служит образцом структурированного документооборота в распределенной среде разработки. Платформа интегрирует реальные процессы проектирования, эксплуатации и сопровождения микросервисной архитектуры, адаптированные для обучения, проверки конфигураций и демонстрации автоматизации.

## Содержание проекта

В проект включены упрощенные, но согласованные описания ключевых компонентов:  
* Архитектура системы (сервисы, взаимодействия, шины событий)  
* Спецификации API (методы, параметры, коды ответов)  
* CI/CD процессы (стадии, инструменты, политики контроля)  
* Операционные процедуры (troubleshooting, управление инцидентами)  
* Интеграционные сценарии (внешние провайдеры, адаптеры)  

## Роль DocOps MCP Assistant

Платформа используется как среда для отладки и демонстрации возможностей ассистента:  
* Автоматическая генерация технической документации по метаданным сервисов  
* Анализ покрытия кода документацией  
* Поддержка семантического поиска по артефактам  
* Контроль соответствия изменений в коде и обновлений документации  
* Формирование сводок по релизам на основе истории коммитов и задач  
Assistant интегрирован в CI/CD и реагирует на события: создание ветки, пул-реквест, деплой.

## Структура хранения и доступа

Документация организована в виде модульных Markdown-файлов, размещенных в Git-репозитории. Связь между файлами и сервисами поддерживается через YAML-манифесты. Версии документации соответствуют тегам релизов. Публичный доступ ограничен; просмотр возможен через встроенный веб-интерфейс или Confluence, синхронизированный через DocOps Sync Agent.

## Применение в процессах

Платформа используется в следующих процессах:
* Обучение новых сотрудников
* Тестирование обновлений DocOps ML Engine
* Валидация шаблонов документирования
* Демонстрация клиентам возможностей системы автоматизации документооборота
        """
    )

    ensure_file(
        demo_repos / "docops-saas" / "docs" / "billing_overview.md",
        """
# Сервис биллинга

## Описание сервиса

Сервис биллинга отвечает за формирование и поддержание финансовых взаимоотношений с пользователями в рамках платной модели платформы. Он реализует ядро монетизации, обеспечивая точность, надежность и аудируемость всех транзакций.

## Архитектура сервиса биллинга

Архитектурно сервис построен по принципам модульности и слабой связанности. Основной компонент — ядро расчетов — отделен от шлюзов оплаты, системы уведомлений и UI-слоя. Взаимодействие между компонентами осуществляется через REST API (внутренние вызовы) и асинхронные сообщения с использованием очередей на базе RabbitMQ. Все критические операции логируются в централизованную систему (например, ELK), а метрики собираются через Prometheus для мониторинга доступности и производительности.

## Основные процессы

Расчет стоимости подписки выполняется на основе тарифных планов, хранящихся в реляционной базе данных (PostgreSQL). Каждый тариф включает параметры: стоимость, периодичность списания, лимиты использования ресурсов, правила проработки овердрафта. Поддерживается гибкая модель ценообразования — flat rate, usage-based, tiered pricing. Для учета потребления используются данные из сервиса метрик, передаваемые по расписанию или в реальном времени.

Генерация счетов происходит по событию начала нового биллингового цикла. Счета формируются в формате JSON и конвертируются в PDF для отправки пользователю. Шаблоны документов хранятся в отдельном хранилище (S3-совместимое), версионируются. Каждый счет имеет уникальный идентификатор, ссылку на тариф, детализацию начислений и статус оплаты.

Управление циклом оплаты включает автоматическое продление подписок, обработку отмен, пробные периоды и grace period. Планировщик задач (Celery Beat) активирует процессы в соответствии с графиком каждого пользователя. При неудачной попытке списания запускается retry-механизм с экспоненциальной задержкой (до трех попыток). После исчерпания попыток подписка переводится в состояние suspended, а пользователь получает уведомление.

## Webhooks и интеграция с внешними системами

Обработка веб-хуков реализована с учетом требования идемпотентности. Входящие запросы от платежных систем (Stripe, PayPal, Yandex.Checkout) валидируются по цифровой подписи, нормализуются и помещаются в очередь на обработку. Сервис подтверждает прием события немедленно, а фактическая обработка происходит асинхронно. Состояние платежа обновляется в базе, запускаются соответствующие триггеры — активация подписки, обновление квот, отправка событий в аналитическую систему.

Состояние сервиса контролируется health check-эндпоинтами, включая проверку соединения с БД, очередями и внешними шлюзами. Развертывание осуществляется в контейнеризованной среде (Docker + Kubernetes), с разделением окружений (dev/stage/prod). Переменные окружения и секреты управляются через Hashicorp Vault.

Интеграция с внешними системами осуществляется через API-адаптеры, что позволяет добавлять новые платежные шлюзы без изменения бизнес-логики. Все внешние вызовы защищены TLS 1.3, реализована защита от DDoS и rate limiting на уровне API Gateway.

## Шифрование

Данные о платежах шифруются при хранении (AES-256) и передаче (TLS). Соответствие требованиям PCI DSS обеспечивается за счет делегирования обработки платежных данных внешним провайдерам; внутри сервиса не хранятся CVV, полные номера карт.
        """
    )

    ensure_file(
        demo_repos / "docops-saas" / "docs" / "auth_service.md",
        """
# Auth-Service (Single Sign-On)

## Назначение и область действия

Auth-Service является централизованным решением для аутентификации и авторизации в экосистеме платформы. Он обеспечивает единое место управления идентификацией пользователя, устраняя необходимость повторной авторизации при переходе между внутренними сервисами. Сервис интегрируется со всеми компонентами, требующими проверки подлинности, включая биллинг, аналитику, административные интерфейсы и API для партнеров.

## Протоколы и стандарты безопасности

Реализация основана на OpenID Connect (OIDC) поверх OAuth 2.0. Поддерживаемые потоки: Authorization Code с PKCE для SPA и мобильных клиентов, Client Credentials для machine-to-machine взаимодействия. Все токены выпускаются в формате JWT (RFC 7519), подписаны алгоритмом RS256. Публичные ключи доступны через JWKS-эндпоинт для внешней валидации. Токены доступа имеют короткий срок жизни — 15 минут, refresh-токены — 7 дней с возможностью ротации.

## Архитектура и компоненты

Сервис реализован на FastAPI с использованием асинхронного стека (Python 3.11, Uvicorn, Gunicorn). Асинхронность позволяет эффективно обрабатывать большое количество параллельных запросов на валидацию токенов и аутентификацию. Состояние сессий хранится в Redis с TTL, соответствующим времени жизни refresh-токена. Redis кластер настроен с репликацией и автоматическим фейловером (Redis Sentinel). Для защиты от brute-force атак реализован rate limiting по IP и user ID.

## Управление сессиями

При успешной аутентификации создается запись в Redis, содержащая идентификатор сессии, время создания, время последнего использования и данные пользователя (user_id, роли, группы). Refresh-токены привязываются к сессии и могут быть отзываемы принудительно. Logout выполняется путем удаления сессии из Redis и добавления токена в черный список (revocation list) с ограниченным временем хранения.

## Интеграция с внешними провайдерами

Поддерживается федеративная аутентификация через Google Workspace, GitHub и SAML 2.0 для корпоративных клиентов. Маппинг ролей осуществляется на основе claims в ID token или атрибутов SAML assertion. Конфигурация внешних провайдеров управляется через консоль администратора с версионированием изменений.

## Безопасность и соответствие требованиям

Все эндпоинты защищены HTTPS с обязательным HSTS. Заголовки безопасности (CORS, Content-Security-Policy) настроены строго под потребности клиентов. Логирование аутентификационных событий ведется в систему SIEM с фильтрацией чувствительных данных. Соответствие стандартам ISO 27001 и GDPR обеспечивается за счет минимального сбора персональных данных и шифрования данных в покое (AES-256).

## Масштабируемость и отказоустойчивость

Сервис развернут в Kubernetes с горизонтальным автомасштабированием на основе CPU и количества запросов. Health check включает проверку доступности Redis и подписывающего ключа. Резервное копирование конфигураций провайдеров и метаданных пользователей выполняется ежедневно в зашифрованном виде.
        """
    )

    ensure_file(
        demo_repos / "docops-saas" / "docs" / "architecture.md",
        """
# Архитектура DocOps-SaaS

## Общая структура и принципы проектирования
Архитектура DocOps-SaaS построена по модели распределенной микросервисной системы с четким разделением ответственности. Основные компоненты взаимодействуют через определенные API и асинхронные события, что обеспечивает независимость развертывания, изоляцию сбоев и гибкость масштабирования. Система ориентирована на высокую доступность, поддержку многопользовательской среды и интеграцию с внешними CI/CD-инструментами.

## Описание компонентов

### Web Frontend (Next.js)

Фронтенд реализован на Next.js с использованием App Router, что позволяет комбинировать серверный рендеринг для SEO и динамическую загрузку контента. Интерфейс взаимодействует с бэкендом через API Gateway, используя REST и WebSocket для обновления состояния в реальном времени. Аутентификация происходит через JWT, полученный от Auth-Service. Статические ресурсы раздаются через CDN, минимизируя задержки при первоначальной загрузке.

### API Gateway (FastAPI)

Единая точка входа для всех клиентских и внутренних запросов. Обеспечивает маршрутизацию, аутентификацию, валидацию входных данных, логирование и rate limiting. Использует декодирование JWT для извлечения контекста пользователя и передачи его в микросервисы через заголовки. Поддерживает OpenAPI-спецификации от каждого сервиса, автоматически генерируя документацию. Реализован как stateless компонент, допускающий горизонтальное масштабирование.

### Billing (Python-микросервис)

Отдельный микросервис, отвечающий за управление подписками, расчетом стоимости использования и выставлением счетов. Взаимодействует с API Gateway для получения событий о потреблении ресурсов и с внешними платежными шлюзами через адаптеры. Данные хранятся в PostgreSQL с репликацией и point-in-time recovery. Все финансовые операции записываются в отдельную audit-таблицу с неизменяемыми записями.

### DocOps ML Engine

Сервис, отвечающий за автоматическую генерацию технической документации на основе исходного кода, комментариев, commit-сообщений и метаданных API. Реализован как отдельное приложение на Python с использованием fine-tuned моделей классификации и генерации текста. Принимает задачи через Event Bus, обрабатывает их и сохраняет результат в документное хранилище. Модели загружаются при старте из объектного хранилища, поддерживают версионирование и A/B тестирование.

### Event Bus (Redis Streams)

Асинхронная шина событий на основе Redis Streams обеспечивает надежную доставку сообщений между сервисами. Каждый микросервис подписывается на интересующие его топики (например, «code.push», «subscription.updated»). Сообщения содержат тип события, идентификатор источника, полезную нагрузку в формате JSON и временные метки. Redis настроен с persistence и replication, чтобы избежать потери событий при перезагрузке. Потребители управляют offset-позицией и могут повторно обрабатывать события при ошибках.

## Распределение документов и кода
 
Документы хранятся в нескольких местах в зависимости от типа:  
* Сгенерированная документация — в S3-совместимом хранилище с версионированием.  
* Исходный код пользователей — в Git-репозиториях (внутренний GitLab или интеграция с GitHub/GitLab.com).  
* Метаданные и ссылки на документы — в PostgreSQL, централизованной для фронтенда и поискового сервиса.  

Код самого приложения распределен по репозиториям, соответствующим каждому микросервису, с единым стандартом CI/CD на основе GitOps.
        """
    )

    ensure_file(
        demo_repos / "docops-saas" / "docs" / "api_gateway.md",
        """
# API Gateway

## Маршрутизация запросов

API Gateway выступает в роли центрального маршрутизатора, принимающего входящие HTTP-запросы от клиентов и перенаправляющего их к соответствующим микросервисам на основе пути (path-based routing). Маршруты конфигурируются динамически через реестр сервисов или статически в конфигурационных файлах. Поддерживается балансировка нагрузки между репликами целевых сервисов с использованием round-robin или least-connections стратегии. Для внутренних вызовов применяется service discovery на основе DNS или etcd.

## Rate limiting

Ограничение частоты запросов реализовано на уровне пользователя (по user_id из JWT) и IP-адреса. Политики rate limiting (например, 1000 запросов в минуту) управляются через конфигурационные правила и могут различаться для разных эндпоинтов. Используется алгоритм token bucket с хранилищем состояний в Redis для согласованности в распределенной среде. Превышение лимита возвращает код 429 с заголовками Retry-After и пояснением причины.

## Валидация схем

Все входные запросы (query параметры, path параметры, тело) проверяются на соответствие заранее определенным схемам, описанным в OpenAPI 3.0. Валидация выполняется до передачи запроса в микросервис. Схемы кэшируются в памяти после загрузки из `/openapi.json` каждого сервиса. При несоответствии возвращается 400 с детализацией поля и типа ошибки. Поддерживается strict mode — запрет дополнительных полей, не объявленных в схеме.

## Управление токенами для внутренних сервисов

API Gateway может запрашивать и кэшировать короткоживущие JWT-токены для взаимодействия с другими сервисами от имени системы (machine-to-machine). Такие токены используют service account с ограниченными правами и выпускаются Auth-Service по клиентским учетным данным (client_credentials flow). Ключи для подписи хранятся в Hashicorp Vault, доступ осуществляется через sidecar-агент. Токены автоматически обновляются при приближении истечения срока.

## OpenAPI-спецификация

Единая точка доступа к документации API расположена по пути `/openapi.json`. Файл агрегируется из спецификаций всех подключенных микросервисов, объединяясь в один валидный документ. Поддерживает теги, securitySchemes и примеры запросов. Доступ к спецификации защищен: открыта только авторизованным пользователям с ролью `developer` или `admin`. На ее основе разворачивается интерактивный Swagger UI при наличии соответствующего флага в окружении.
        """
    )

    ensure_file(
        demo_repos / "docops-saas" / "docs" / "ci_cd.md",
        """
# CI/CD Pipeline

Пайплайн CI/CD состоит из следующих этапов:
1. Линтинг и тестирование.
2. Сборка Docker-образа.
3. Проверка безопасности.
4. Деплой.
5. Ручное подтверждение.
6. Деплой в production.

Описание этих этапов представлено в соответствующих разделах ниже.

## Линтинг и тестирование

На первой стадии выполняются проверки качества кода и его работоспособности. Запускаются линтеры (flake8, black, mypy для Python; ESLint/Prettier для фронтенда), проверяется соответствие pre-commit-хукам. Параллельно запускается полный набор тестов: unit, integration и smoke-тесты с изолированным окружением через pytest и Testcontainers. Тесты выполняются в матрице конфигураций при необходимости (разные версии Python, ОС). Провал на этой стадии останавливает конвейер.

## Сборка Docker-образа

При успешном прохождении тестов инициируется сборка образа. Используется multi-stage Dockerfile для минимизации размера финального образа. Образ помечается по шаблону: `{service}:{git-sha}` или `{service}:latest` для основной ветви. Сборка происходит в изолированной среде GitHub Actions с кэшированием слоев. Результат загружается в приватный container registry (например, GitHub Container Registry или внутренний Harbor).

## Проверка безопасности

Образ анализируется на наличие уязвимостей в зависимостях и конфигурационных ошибках. Используются инструменты: Trivy для сканирования образов, Snyk или OWASP Dependency-Check для анализа manifest-файлов. Проверяется наличие секретов в коде (через git-secrets или detect-secrets). Найденные уязвимости высокого уровня (CVSS ≥ 7.0) блокируют переход к следующей стадии. Отчеты сохраняются как артефакты и доступны для аудита.

## Деплой

После успешного сканирования ArgoCD применяет манифесты Kubernetes (Helm charts или Kustomize) в staging-кластере. Деплой выполняется через push-механизм: GitHub Actions обновляет GitOps-репозиторий с новым тегом образа, ArgoCD обнаруживает изменение и синхронизирует состояние кластера. После деплоя запускаются end-to-end тесты, проверяющие работоспособность сервиса в среде, максимально приближенной к production.

## Ручное подтверждение

Перед выпуском в production требуется ручное подтверждение от назначенного ответственного (обычно tech lead или release manager). Уведомление отправляется в Slack или email. Подтверждение реализовано через GitHub Environments с возможностью добавления комментария. На этом этапе можно отменить или отложить релиз без изменения кода.

## Деплой в production

После одобрения запускается автоматический деплой в production-кластер. ArgoCD применяет те же манифесты, что и в staging, с учетом различий в конфигурации (env-specific overlays). Деплой выполняется стратегией rolling update с health check-проверками readiness/liveness. Мониторинг за состоянием сервиса активируется сразу после старта подов — система собирает метрики и логи для быстрого выявления аномалий. В случае сбоя возможен автоматический rollback через Argo Rollouts или ручное восстановление предыдущей версии.
        """
    )

    ensure_file(
        demo_repos / "docops-saas" / "docs" / "ml_engine.md",
        """
# DocOps ML Engine

## Назначение и функциональность

ML Engine является централизованным компонентом для автоматизации работы с технической документацией. Он обрабатывает структурированные и неструктурированные данные из репозиториев кода, систем управления знаниями (Confluence) и CI/CD-истории. Основные функции включают: генерацию документации по коду, создание сводок изменений при релизах, оценку степени покрытия кода документацией и семантический поиск по всем текстовым артефактам.

## Генерация технической документации

На вход подается AST (abstract syntax tree) исходного кода, комментарии, нейминг функций и метаданные API. Модель на основе fine-tuned LLM преобразует эти данные в структурированный текст в формате Markdown. Генерация выполняется по шаблонам, соответствующим внутренним стандартам документирования. Результат включает описание модулей, параметров, примеры вызова и зависимости. Выходные данные кэшируются и инвалидируются при изменении связанного кода.

## Автоматические Release Notes для релизов

При каждом тегировании релиза в Git система анализирует commit messages, Jira-тикеты, pull request-описания и изменения в коде. На основе этого формируется краткая сводка: список измененных компонентов, тип изменений (feature, fix, deprecation), затронутые сервисы и рекомендации по миграции. Сводка передается в уведомления, публикуется в Confluence и прикрепляется к GitHub Release.

## Анализ покрытия документацией

Для каждого репозитория вычисляется метрика покрытия — отношение количества задокументированных модулей к общему числу публичных интерфейсов. Анализ включает проверку наличия README, описания API-эндпоинтов, примеров использования. Результат интегрируется в CI: при значительном снижении показателя конвейер может быть заблокирован или переведен в режим предупреждения. Отчет доступен через веб-интерфейс и API.

## Семантический поиск по коду и Confluence

Реализован на основе векторного поиска. Тексты из исходного кода, комментариев, документации и страниц Confluence преобразуются в эмбеддинги с использованием OpenAI Embeddings (например, text-embedding-ada-002). Векторы сохраняются в локальном индексе Faiss, оптимизированном для быстрого поиска по схожести. По запросу пользователя система находит наиболее релевантные фрагменты вне зависимости от точного совпадения терминов. Поддерживается фильтрация по источнику (только код, только Confluence) и проекту.

## Интеграция и выполнение задач

ML Engine получает задачи асинхронно через Event Bus (Redis Streams). Каждая задача содержит тип операции, ссылку на источник данных (Git SHA, page ID) и контекст пользователя. Обработка происходит в worker-процессах с управлением очередью и retry-логикой. Для масштабирования используются несколько инстансов с общим индексом, размещенным в сетевом хранилище. Индекс периодически обновляется в off-peak часы.

## Производительность и безопасность

Запросы к внешним LLM минимизированы за счет кэширования и батчинга. Все чувствительные данные (ключи, приватный код) остаются внутри внутренней сети. При работе с внешними API применяется прокси с аудитом и rate limiting. Эмбеддинги хранятся в зашифрованном виде, доступ к индексу контролируется через IAM-политики.
        """
    )

    ensure_file(
        demo_repos / "docops-saas" / "docs" / "troubleshooting.md",
        """
# Troubleshooting

В ходе эксплуатации могут возникать следующие ошибки:
1. JWT expired.
2. 429 too many requests.
3. Billing webhook signature mismatch.

Подробное описание этих ошибок, а также способов их устранения, проедставлено в разделах ниже.

## JWT expired

Ошибка возникает при попытке доступа к защищенному эндпоинту с просроченным access token. Токены имеют короткий срок жизни (обычно 15 минут). Решение — использовать refresh token для получения новой пары токенов через эндпоинт `/auth/refresh`. Refresh token должен быть действителен и не отозван. Если refresh token также истек, требуется повторная аутентификация. Клиентские приложения должны реализовать перехват 401 и автоматическое обновление с последующей повторной отправкой запроса.

## 429 too many requests

Сервис возвращает статус 429 при превышении лимита запросов, определенного политикой rate limiting. Причина — превышение допустимой частоты вызовов по IP-адресу или user_id. Для устранения необходимо проверить текущую нагрузку на клиенте, внедрить backoff-логику (например, экспоненциальный retry) и оптимизировать количество запросов. В случае необходимости увеличения квоты администратор может скорректировать правила в конфигурации API Gateway. Заголовки ответа содержат `X-RateLimit-Limit`, `X-RateLimit-Remaining` и `Retry-After`.

## Billing webhook signature mismatch

Ошибка указывает на несоответствие цифровой подписи входящего веб-хука о платеже. Возникает при использовании неверного секрета для валидации HMAC-SHA256 хэша тела запроса. Необходимо сверить значение секрета, настроенного в платежном шлюзе (например, Stripe), с тем, что хранится в системе (в Vault или переменных окружения Billing-сервиса). Секрет чувствителен к пробелам и регистру. После изменения — пересоздать endpoint в интерфейсе провайдера, чтобы обновить подпись. Также следует проверить, что тело запроса перед валидацией не модифицируется (например, преобразуется в JSON с потерей форматирования).
        """
    )

    # ------------------------------------------------------------------------------------
    # AIRPORT-FOOD — документация процессов доставки в бизнес-залы
    # ------------------------------------------------------------------------------------
    ensure_file(
        demo_repos / "airport-food" / "README.md",
        """
# Airport Food Delivery

## Общее описание

Airport Food Delivery — специализированный сервис, обеспечивающий заказ и доставку еды из ресторанов аэропорта в бизнес-залы для пассажиров и персонала. Интегрирован с внутренними системами управления терминалами, службами кейтеринга и платформой DocOps для контроля документооборота, стандартных операционных процедур (SOP) и процессов изменения конфигурации.

## Рабочие процессы и интеграции

Пользователь делает заказ через мобильное приложение или стойку самообслуживания. Заказ передается в ближайший подходящий ресторан через внутренний API кейтеринга. Система учитывает время прибытия пассажира (из данных посадки), доступность блюд и SLA доставки (не более 15 минут). Уведомления о статусе отправляются через push и SMS.

Доставка выполняется персоналом с использованием тележек с геолокацией. Каждый этап — принятие заказа, приготовление, передача курьеру, доставка — фиксируется в системе как событие. При отклонении от графика запускается корректирующее действие: переориентация на другой ресторан или уведомление администратора зала.

## Управление процессами через DocOps

Все операционные процессы формализованы и хранятся в DocOps. Это включает:  
— Стандартные процедуры обработки заказов (SOP)  
— Чек-листы для персонала кейтеринга  
— Планы реагирования на сбои (например, недоступность ресторана)  
— Руководства по интеграции новых ресторанов  

DocOps автоматически связывает документы с версиями сервисов и релизами. При обновлении логики заказа система проверяет, что соответствующая документация актуальна. Если нет — блокирует деплой до обновления.

## Контроль изменений и аудит

Любое изменение в конфигурации (например, добавление нового ресторана, изменение времени доставки) проходит через процесс Change Request в DocOps. Запрос включает описание изменений, затронутые системы, ответственных и план отката. После одобрения — изменения применяются, а документация обновляется автоматически на основе шаблонов. Все действия логируются для аудита.

## Мониторинг и аналитика

Сервис собирает метрики по времени выполнения заказа, отказам, нагрузке. Данные используются для оптимизации маршрутов доставки и прогнозирования спроса. Отчеты и дашборды доступны в Confluence через интеграцию с BI-системой. DocOps ML Engine анализирует текстовые отчеты и генерирует сводки по инцидентам.
        """
    )

    ensure_file(
        demo_repos / "airport-food" / "docs" / "process_overview.md",
        """
# Общая схема процесса доставки

## Этап 1: Оформление заказа

Гость выбирает блюда через мобильное приложение или терминал в зале. Заказ включает идентификатор гостя, номер посадки, выбранные позиции, время подачи и особые пожелания (например, аллергены). Данные передаются в центральную систему управления заказами (Order Management Service), которая проверяет доступность ресторана и актуальность меню.

## Этап 2: Подтверждение готовности кухни

Система направляет заказ на кухню выбранного ресторана. Оператор ресторана подтверждает принятие заказа в интерфейсе. После завершения приготовления он отмечает статус «готов к выдаче». Время фиксируется с точностью до секунды. Если блюдо недоступно, заказ аннулируется, гость уведомляется автоматически.

## Этап 3: Доставка курьером

Центральный диспетчер (на основе геопозиции и загрузки) назначает курьера. Курьер получает задание через мобильное приложение, забирает заказ у ресторана и доставляет в указанный бизнес-зал. Маршрут и текущее местоположение отслеживаются в реальном времени. При превышении порога в 18 минут система активирует оповещение диспетчеру.

## Этап 4: Прием и проверка заказа

Менеджер бизнес-зала принимает заказ, сверяя содержимое с накладной (в приложении и на печати). Проверяется соответствие блюд, температурный режим и внешний вид упаковки. После подтверждения приема статус заказа меняется на «доставлен». В случае расхождений — создается инцидент, который регистрируется в системе мониторинга качества.

## Нормативное время доставки

Общий цикл — от оформления до приема — должен укладываться в **15–22 минуты**. Превышение лимита фиксируется как SLA-breach, инициируя анализ причины (задержка на кухне, перегрузка курьера, транспортные помехи). Данные используются для ежемесячной оценки эффективности ресторанов и курьерской службы.
        """
    )

    ensure_file(
        demo_repos / "airport-food" / "docs" / "restaurant_integration.md",
        """
# Интеграция с ресторанами

## POS API — прием заказов

Система отправляет заказ в ресторан через унифицированный POS API, который абстрагирован от конкретной реализации кассовой системы. Запрос содержит идентификатор заказа, список блюд с модификаторами, время подачи и специальные отметки (например, «без глютена»). Ответ должен подтвердить прием заказа в течение 5 секунд. При неудаче — активируется retry-механизм с экспоненциальной задержкой до трех попыток.

## Адаптер для различных POS-систем

Поскольку рестораны используют разные платформы (например, iiko, Toast, Oracle MICROS), прямая интеграция невозможна без стандартизации. Реализован шаблон «адаптер», где каждый провайдер имеет собственный коннектор, транслирующий вызовы из внутреннего формата в специфичный для POS. Адаптеры развернуты как отдельные микросервисы или в составе единого routing-сервиса. Все они реализуют единый интерфейс, что позволяет добавлять новые рестораны без изменений в ядре системы.

## Kitchen Display System (KDS) — контроль готовности

После приема заказа он появляется на экране KDS кухни. Система Airport Food Delivery опрашивает KDS с интервалом 10–30 секунд (в зависимости от загрузки) для получения статуса: «в обработке», «готов», «отменен». Изменение статуса триггерит событие в Event Bus, которое используется для планирования доставки. Интеграция с KDS может быть прямой (через WebSocket) или через промежуточный сервер синхронизации.

## Loyalty API — начисление бонусов

После успешной доставки запускается процесс начисления бонусов клиенту. Вызов выполняется к внешнему Loyalty API авиакомпании или аэропорта. Передается идентификатор участника программы, сумма заказа и тип операции. Ошибка в начислении не блокирует завершение заказа, но фиксируется как background-инцидент для последующего ручного восстановления. Ответ от Loyalty API логируется для аудита.

## Обеспечение надежности и совместимости

Все внешние вызовы выполняются асинхронно через очередь задач. Таймауты строго ограничены (обычно 10 секунд). При постоянной недоступности POS или KDS система переводит ресторан в состояние «временно недоступен» и перенаправляет заказы. Версии адаптеров версионируются, поддерживают обратную совместимость. Конфигурация подключения (URL, токены, режимы) управляется централизованно через консоль администрирования.
        """
    )

    ensure_file(
        demo_repos / "airport-food" / "docs" / "api_specs.md",
        """
# Airport Food Delivery API

**Базовый URL**: `https://api.airport-food-delivery.example/v1`

## Аутентификация
Используется Bearer-токен на основе JWT. Токен получается через Auth-Service по OIDC flow. Все эндпоинты требуют наличия заголовка:  
`Authorization: Bearer <token>`

## Эндпоинты

### Создание нового заказа

**POST /orders**

*Запрос:*  
```json
{
  "guest_id": "string",
  "flight_number": "SU102",
  "gate": "B12",
  "items": [
    {
      "menu_id": "m_123",
      "quantity": 1,
      "notes": "без соли"
    }
  ],
  "delivery_location": "Premier Lounge Terminal C"
}
```

*Ответ при успехе (201):*  
```json
{
  "order_id": "ord_456789",
  "status": "created",
  "estimated_delivery_time": "2025-11-23T15:45:00Z",
  "qr_code": "https://qrcode.example/ord_456789"
}
```

### Получение статуса заказа

**GET /orders/{order_id}**

*Ответ:*  
```json
{
  "order_id": "ord_456789",
  "status": "delivered",
  "items": [
    {
      "menu_id": "m_123",
      "name": "Цезарь с курицей",
      "quantity": 1
    }
  ],
  "timestamps": {
    "created": "2025-11-23T15:20:00Z",
    "kitchen_accepted": "2025-11-23T15:22:10Z",
    "in_transit": "2025-11-23T15:30:05Z",
    "delivered": "2025-11-23T15:42:30Z"
  },
  "courier_id": "cr_007",
  "delivery_location": "Premier Lounge Terminal C"
}
```

Возможные статусы: `created`, `accepted`, `in_transit`, `delivered`, `cancelled`.

### Аннулирование заказа

**PUT /orders/{order_id}/cancel**

Примечание: доступно только до статуса `in_transit`.

*Ответ при успехе (200):*  
```json
{
  "order_id": "ord_456789",
  "status": "cancelled",
  "cancellation_reason": "guest_not_found"
}
```

Поддерживаемые причины: `guest_changed_mind`, `flight_departed`, `guest_not_found`, `item_unavailable`.

### Получение списка доступных ресторанов в текущем терминале

**GET /restaurants/available**

*Ответ (200):*  
```json
[
  {
    "restaurant_id": "r_001",
    "name": "Sky Bistro",
    "cuisine": "international",
    "avg_preparation_time_min": 12,
    "is_available": true
  }
]
```

## Ошибки
Все ошибки возвращаются в формате:  
```json
{
  "error": "invalid_request",
  "message": "Order exceeds maximum allowed preparation time"
}
```

Коды HTTP:  
* `400` — неверный запрос  
* `401` — токен недействителен  
* `403` — доступ запрещен  
* `404` — заказ или ресторан не найден  
* `429` — превышен лимит запросов  
* `500` — внутренняя ошибка сервиса

## Мониторинг и документация
Health check: `GET /health` — возвращает 200 при готовности.  
OpenAPI-спецификация доступна по `/openapi.json`.  
Эндпоинты логируются, метрики собираются в Prometheus.
        """
    )

    ensure_file(
        demo_repos / "airport-food" / "docs" / "incident_management.md",
        """
# Управление инцидентами

## Длительная доставка

Инцидент фиксируется автоматически при превышении 22 минут с момента оформления заказа. Система определяет стадию задержки: ожидание на кухне, отсутствие курьера, простой в пути. Отчет содержит временные метки, идентификаторы ресторана, курьера и бизнес-зала. В Slack отправляется сообщение в канал #incidents с тегом ответственного (диспетчер или менеджер зала). Причины анализируются ежемесячно для корректировки SLA и перераспределения ресурсов.

## Потеря заказа

Фиксируется, если заказ не подтвержден на стадии приема менеджером зала в течение 30 минут после готовности. Возможные причины — ошибка курьера, сбой в системе отслеживания. Отчет включает маршрут движения, логи связи с курьером, данные о последнем местоположении. Уведомление в Slack помечается как high priority. Запускается процесс компенсации: повторная доставка или списание бонусов. Инцидент требует подтверждения закрытия от администратора.

## Несоответствие блюда

Регистрируется при ручной проверке в зале, если состав заказа не совпадает с накладной. Менеджер фиксирует расхождение через интерфейс, прикладывая фото. Отчет содержит идентификатор заказа, список несоответствующих позиций, данные о кухне и времени приготовления. Уведомление направляется в канал #kitchen-feedback с участием операционного менеджера. Данные используются для аудита качества ресторанов и переобучения персонала.

## Гость не найден

Возникает, если гость не находится в указанном зале в момент доставки (например, ушел на посадку). Проверка осуществляется по данным терминала (gate assignment, boarding time). Система предварительно оценивает риски до отправки заказа. При подтверждении — формируется отчет с временем прибытия гостя и фактическим местоположением. Уведомление в Slack включает рекомендацию: хранение заказа до 15 минут или аннулирование. Блюда утилизируются с фиксацией в журнале.

## Общая обработка инцидентов

Каждый инцидент получает уникальный ID, привязывается к заказу и пользователю. Отчет генерируется автоматически на основе событий из Event Bus и логов сервисов. Структура отчета: тип, время возникновения, затронутые компоненты, цепочка событий, ответственные. Все уведомления в Slack содержат ссылку на полный отчет в Confluence и кнопку для перехода в режим расследования. Инциденты классифицируются по уровню серьезности и попадают в еженедельный дашборд для анализа.
        """
    )

    print(f"Demo repos seeded under: {demo_repos}")


if __name__ == "__main__":
    main()